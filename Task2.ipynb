{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f40cbfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drugY    91\n",
      "drugX    54\n",
      "drugA    23\n",
      "drugC    16\n",
      "drugB    16\n",
      "Name: Drug, dtype: int64\n",
      "{'drugY': 91, 'drugX': 54, 'drugA': 23, 'drugC': 16, 'drugB': 16}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report #7c\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#QUETION 2\n",
    "df = pd.read_csv(\"C:/Users/aminn/Desktop/Task2/drug200.csv\")\n",
    "print(df['Drug'].value_counts())\n",
    "value_list = df['Drug'].value_counts()\n",
    "data_dict = value_list.to_dict()\n",
    "print(data_dict)\n",
    "\n",
    "myfig = plt.plot(data_dict.keys(), data_dict.values(), 'bo')\n",
    "plt.savefig(\"drug-distribution.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b757bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        HIGH\n",
      "1         LOW\n",
      "2         LOW\n",
      "3      NORMAL\n",
      "4         LOW\n",
      "        ...  \n",
      "195       LOW\n",
      "196       LOW\n",
      "197    NORMAL\n",
      "198    NORMAL\n",
      "199       LOW\n",
      "Name: BP, Length: 200, dtype: category\n",
      "Categories (3, object): ['LOW' < 'NORMAL' < 'HIGH']\n",
      "   Age Sex  BP Cholesterol  Na_to_K   Drug\n",
      "0   23   F   2        HIGH   25.355  drugY\n",
      "1   47   M   0        HIGH   13.093  drugC\n",
      "2   47   M   0        HIGH   10.114  drugC\n",
      "3   28   F   1        HIGH    7.798  drugX\n",
      "4   61   F   0        HIGH   18.043  drugY\n",
      "   Age  BP  Na_to_K   Drug  Sex_F  Sex_M  Cholesterol_HIGH  Cholesterol_NORMAL\n",
      "0   23   2   25.355  drugY      1      0                 1                   0\n",
      "1   47   0   13.093  drugC      0      1                 1                   0\n",
      "2   47   0   10.114  drugC      0      1                 1                   0\n",
      "3   28   1    7.798  drugX      1      0                 1                   0\n",
      "4   61   0   18.043  drugY      1      0                 1                   0\n"
     ]
    }
   ],
   "source": [
    "# Question 4    \n",
    "df = pd.read_csv(\"C:/Users/aminn/Desktop/Task2/drug200.csv\")\n",
    "df.BP = pd.Categorical(df.BP, ['LOW', 'NORMAL', 'HIGH'], ordered= True)\n",
    "print(df.BP)\n",
    "df.BP = df.BP.cat.codes\n",
    "print(df.head())\n",
    "data_final = pd.get_dummies(df, columns=['Sex', 'Cholesterol'])\n",
    "print(data_final.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58bc0658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>drugA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>drugA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>drugA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Drug\n",
       "171  drugX\n",
       "101  drugA\n",
       "123  drugY\n",
       "177  drugY\n",
       "100  drugA\n",
       "..     ...\n",
       "141  drugY\n",
       "97   drugY\n",
       "21   drugY\n",
       "63   drugX\n",
       "140  drugA\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 5 Splitting    \n",
    "Y = data_final[['Drug']]\n",
    "X = data_final[['Age', 'BP', 'Na_to_K', 'Sex_F', 'Sex_M', 'Cholesterol_HIGH', 'Cholesterol_NORMAL']]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)\n",
    "# X_train : prints out the x_train\n",
    "#Y_train #prints out the y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bee86df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Criterion:  gini\n",
      "Best Max_depth:  4\n",
      "Best Min_amples_split:  6\n"
     ]
    }
   ],
   "source": [
    "# Question 6.a\n",
    "from sklearn import tree\n",
    "\n",
    "gNB = GaussianNB()\n",
    "gNB.fit(X_train, Y_train.values.ravel())\n",
    "GPredict = gNB.predict(X_test)\n",
    "\n",
    "#6.b\n",
    "dt_base = DecisionTreeClassifier()\n",
    "dt_base.fit(X_train, Y_train)\n",
    "classPredictBaseDT = dt_base.predict(X_test)\n",
    "\n",
    "#6.c\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2, 4]\n",
    "min_samples_split = [6, 12, 20]\n",
    "\n",
    "parameters = {'criterion' : criterion, 'max_depth' : max_depth, 'min_samples_split' : min_samples_split}\n",
    "gs = GridSearchCV(decisionTree, param_grid =parameters)\n",
    "gs.fit(X_train, Y_train)\n",
    "\n",
    "print('Best Criterion: ', gs.best_estimator_.get_params()['criterion'])\n",
    "print('Best Max_depth: ', gs.best_estimator_.get_params()['max_depth'])\n",
    "print('Best Min_amples_split: ', gs.best_estimator_.get_params()['min_samples_split'])\n",
    "\n",
    "dt_top = DecisionTreeClassifier(criterion='gini', max_depth=4, min_samples_split=6)\n",
    "dt_top.fit(X_train, Y_train)\n",
    "classPredictTopDT = dt_top.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "be813226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aminn\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Question 6.d Perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "PER = Perceptron()\n",
    "PER.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "classPredictPER = PER.predict(X_test)\n",
    "\n",
    "#Question 6.e Base-MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='sgd')\n",
    "mlp.fit(X_train, Y_train.values.ravel())\n",
    "classPredMLP_base = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3d50115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best activation Function:  logistic\n",
      "Best network architecture:  (30, 50)\n",
      "Best solver:  adam\n"
     ]
    }
   ],
   "source": [
    "#Question 6.f TOP-MLP\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "activation_func = ['logistic', 'tanh', 'relu', 'identity']\n",
    "network_arch1 = [(30, 50), (10, 10, 10)]\n",
    " \n",
    "solver_ = ['adam', 'sgd']\n",
    "mlp_t = MLPClassifier(max_iter=4000)\n",
    "parameters_ = {'activation' : activation_func, 'hidden_layer_sizes' : network_arch1, 'solver' : solver_}\n",
    "gs_mlp = GridSearchCV(mlp_t, param_grid =parameters_)\n",
    "gs_mlp.fit(X_train, Y_train.values.ravel())\n",
    "\n",
    "print('Best activation Function: ', gs_mlp.best_estimator_.get_params()['activation'])\n",
    "print('Best network architecture: ', gs_mlp.best_estimator_.get_params()['hidden_layer_sizes'])\n",
    "print('Best solver: ', gs_mlp.best_estimator_.get_params()['solver'])\n",
    "classPredMLP_top = gs_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b36f145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 7\n",
      "Model a: Gaussian Naive bayes\n",
      "b) The Confusion matrix\n",
      "[[ 0  2  1  1  1]\n",
      " [ 1  0  0  0  2]\n",
      " [ 1  0  1  1  3]\n",
      " [ 1  0  2  2  5]\n",
      " [ 2  0  5  9 10]] \n",
      "\n",
      "c) Precision, Recall, and F1-measure using the Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.00      0.00      0.00         5\n",
      "       drugB       0.00      0.00      0.00         3\n",
      "       drugC       0.11      0.17      0.13         6\n",
      "       drugX       0.15      0.20      0.17        10\n",
      "       drugY       0.48      0.38      0.43        26\n",
      "\n",
      "    accuracy                           0.26        50\n",
      "   macro avg       0.15      0.15      0.15        50\n",
      "weighted avg       0.29      0.26      0.27        50\n",
      "\n",
      "D) Accuracy, Macro-Average F1 and Weighted-Average F1\n",
      "Accuracy =  0.26\n",
      "MacroF1score =  0.14655565834104223\n",
      "WeightedF1score =  0.272059204440333\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Question 7)\n",
    "print('Question 7')\n",
    "print('Model a: Gaussian Naive bayes')\n",
    "print('b) The Confusion matrix')\n",
    "ConfusionMatrix1 = metrics.confusion_matrix(Y_test, GPredict)\n",
    "print(ConfusionMatrix1, '\\n')\n",
    "print('c) Precision, Recall, and F1-measure using the Classification Report')\n",
    "print(classification_report(Y_test, GPredict))\n",
    "print('d) Accuracy, Macro-Average F1 and Weighted-Average F1')\n",
    "gaussAccuracy = metrics.accuracy_score(Y_test, GPredict)\n",
    "gaussMacroF1score = f1_score(Y_test, GPredict, average='macro')\n",
    "gaussWeightedF1score = f1_score(Y_test, GPredict, average='weighted')\n",
    "\n",
    "print('Accuracy = ', gaussAccuracy)\n",
    "print('MacroF1score = ', gaussMacroF1score)\n",
    "print('WeightedF1score = ', gaussWeightedF1score)\n",
    "print('--------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fdff7981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model b: Base-DT\n",
      "b) The Confusion matrix\n",
      "[[ 0  1  0  1  3]\n",
      " [ 0  0  0  0  3]\n",
      " [ 1  0  0  1  4]\n",
      " [ 1  0  1  3  5]\n",
      " [ 2  0  3 10 11]] \n",
      "\n",
      "c) Precision, Recall, and F1-measure using the Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.00      0.00      0.00         5\n",
      "       drugB       0.00      0.00      0.00         3\n",
      "       drugC       0.00      0.00      0.00         6\n",
      "       drugX       0.20      0.30      0.24        10\n",
      "       drugY       0.42      0.42      0.42        26\n",
      "\n",
      "    accuracy                           0.28        50\n",
      "   macro avg       0.12      0.14      0.13        50\n",
      "weighted avg       0.26      0.28      0.27        50\n",
      "\n",
      "d) Accuracy, Macro-Average F1 and Weighted-Average F1\n",
      "Accuracy =  0.28\n",
      "MacroF1score =  0.13261538461538463\n",
      "WeightedF1score =  0.268\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Model b: Base-DT')\n",
    "print('b) The Confusion matrix')\n",
    "ConfusionMatrix2 = metrics.confusion_matrix(Y_test, classPredictBaseDT)\n",
    "print(ConfusionMatrix2, '\\n')\n",
    "print('c) Precision, Recall, and F1-measure using the Classification Report')\n",
    "print(classification_report(Y_test, classPredictBaseDT))\n",
    "print('d) Accuracy, Macro-Average F1 and Weighted-Average F1')\n",
    "dtAccuracy = metrics.accuracy_score(Y_test, classPredictBaseDT)\n",
    "dtMacroF1score = f1_score(Y_test, classPredictBaseDT, average='macro')\n",
    "dtWeightedF1score = f1_score(Y_test, classPredictBaseDT, average='weighted')\n",
    "\n",
    "print('Accuracy = ', dtAccuracy)\n",
    "print('MacroF1score = ', dtMacroF1score)\n",
    "print('WeightedF1score = ', dtWeightedF1score)\n",
    "print('--------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "57dc26e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model c: Top-DT\n",
      "Hyper parameters values changed: \n",
      "criterion: gini/entropy, max_depth = 2, 4 and min_samples_split = 6, 12, 20\n",
      "Best hyper parameters found: \n",
      "b) The Confusion matrix\n",
      "[[ 5  0  0  0  0]\n",
      " [ 0  3  0  0  0]\n",
      " [ 0  0  6  0  0]\n",
      " [ 0  0  0 10  0]\n",
      " [ 0  0  0  0 26]] \n",
      "\n",
      "c) Precision, Recall, and F1-measure using the Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       1.00      1.00      1.00         5\n",
      "       drugB       1.00      1.00      1.00         3\n",
      "       drugC       1.00      1.00      1.00         6\n",
      "       drugX       1.00      1.00      1.00        10\n",
      "       drugY       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n",
      "d) Accuracy, Macro-Average F1 and Weighted-Average F1\n",
      "Accuracy =  1.0\n",
      "MacroF1score =  1.0\n",
      "WeightedF1score =  1.0\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Model c: Top-DT')\n",
    "print('Hyper parameters values changed: ')\n",
    "print('criterion: gini/entropy, max_depth = 2, 4 and min_samples_split = 6, 12, 20')\n",
    "print('Best hyper parameters found: ')\n",
    "print('b) The Confusion matrix')\n",
    "ConfusionMatrix3 = metrics.confusion_matrix(Y_test, classPredictTopDT)\n",
    "print(ConfusionMatrix3, '\\n')\n",
    "print('c) Precision, Recall, and F1-measure using the Classification Report')\n",
    "print(classification_report(Y_test, classPredictTopDT))\n",
    "print('d) Accuracy, Macro-Average F1 and Weighted-Average F1')\n",
    "topDTAccuracy = metrics.accuracy_score(Y_test, classPredictTopDT)\n",
    "topDTMacroF1score = f1_score(Y_test, classPredictTopDT, average='macro')\n",
    "topDTWeightedF1score = f1_score(Y_test, classPredictTopDT, average='weighted')\n",
    "\n",
    "print('Accuracy = ', topDTAccuracy)\n",
    "print('MacroF1score = ', topDTMacroF1score)\n",
    "print('WeightedF1score = ', topDTWeightedF1score)\n",
    "print('--------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3a5090a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model d: Perceptron\n",
      "b) The Confusion matrix\n",
      "[[ 2  3  0  0  0]\n",
      " [ 0  3  0  0  0]\n",
      " [ 0  4  0  1  1]\n",
      " [ 1  4  0  2  3]\n",
      " [ 0  3  0  8 15]] \n",
      "\n",
      "c) Precision, Recall, and F1-measure using the Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.67      0.40      0.50         5\n",
      "       drugB       0.18      1.00      0.30         3\n",
      "       drugC       0.00      0.00      0.00         6\n",
      "       drugX       0.18      0.20      0.19        10\n",
      "       drugY       0.79      0.58      0.67        26\n",
      "\n",
      "    accuracy                           0.44        50\n",
      "   macro avg       0.36      0.44      0.33        50\n",
      "weighted avg       0.52      0.44      0.45        50\n",
      "\n",
      "d) Accuracy, Macro-Average F1 and Weighted-Average F1\n",
      "Accuracy =  0.44\n",
      "MacroF1score =  0.3314285714285714\n",
      "WeightedF1score =  0.4527619047619047\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aminn\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aminn\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aminn\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Model d: Perceptron')\n",
    "print('b) The Confusion matrix')\n",
    "ConfusionMatrix4 = metrics.confusion_matrix(Y_test, classPredictPER)\n",
    "print(ConfusionMatrix4, '\\n')\n",
    "print('c) Precision, Recall, and F1-measure using the Classification Report')\n",
    "print(classification_report(Y_test, classPredictPER))\n",
    "print('d) Accuracy, Macro-Average F1 and Weighted-Average F1')\n",
    "perAccuracy = metrics.accuracy_score(Y_test, classPredictPER)\n",
    "perMacroF1score = f1_score(Y_test, classPredictPER, average='macro')\n",
    "perWeightedF1score = f1_score(Y_test, classPredictPER, average='weighted')\n",
    "\n",
    "print('Accuracy = ', perAccuracy)\n",
    "print('MacroF1score = ', perMacroF1score)\n",
    "print('WeightedF1score = ', perWeightedF1score)\n",
    "print('--------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d4165725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model e: Base MLP\n",
      "b) The Confusion matrix\n",
      "[[ 0  0  0  2  3]\n",
      " [ 0  0  0  3  0]\n",
      " [ 0  0  0  4  2]\n",
      " [ 0  0  0  4  6]\n",
      " [ 0  0  0  3 23]] \n",
      "\n",
      "c) Precision, Recall, and F1-measure using the Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       0.00      0.00      0.00         5\n",
      "       drugB       0.00      0.00      0.00         3\n",
      "       drugC       0.00      0.00      0.00         6\n",
      "       drugX       0.25      0.40      0.31        10\n",
      "       drugY       0.68      0.88      0.77        26\n",
      "\n",
      "    accuracy                           0.54        50\n",
      "   macro avg       0.19      0.26      0.21        50\n",
      "weighted avg       0.40      0.54      0.46        50\n",
      "\n",
      "d) Accuracy, Macro-Average F1 and Weighted-Average F1\n",
      "Accuracy =  0.54\n",
      "MacroF1score =  0.21487179487179486\n",
      "WeightedF1score =  0.46020512820512816\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aminn\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aminn\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\aminn\\miniconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Model e: Base MLP')\n",
    "print('b) The Confusion matrix')             \n",
    "ConfusionMatrix5 = metrics.confusion_matrix(Y_test, classPredMLP_base)\n",
    "print(ConfusionMatrix5, '\\n')\n",
    "print('c) Precision, Recall, and F1-measure using the Classification Report')\n",
    "print(classification_report(Y_test, classPredMLP_base))\n",
    "print('d) Accuracy, Macro-Average F1 and Weighted-Average F1')\n",
    "Accuracy5 = metrics.accuracy_score(Y_test, classPredMLP_base)\n",
    "MacroF1score5 = f1_score(Y_test, classPredMLP_base, average='macro')\n",
    "WeightedF1score5 = f1_score(Y_test, classPredMLP_base, average='weighted')\n",
    "\n",
    "print('Accuracy = ', Accuracy5)\n",
    "print('MacroF1score = ', MacroF1score5)\n",
    "print('WeightedF1score = ', WeightedF1score5)\n",
    "print('--------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "27c655bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model f: Top MLP\n",
      "b) The Confusion matrix\n",
      "Hyperparameter values: \n",
      "solver = adam, sgd; Activation function = logistic, tanh, relu, identity\n",
      "network architecture = (30, 50), (10, 10, 10)\n",
      "Best hyperparameters found:\n",
      "[[ 5  0  0  0  0]\n",
      " [ 0  2  0  0  1]\n",
      " [ 0  0  5  1  0]\n",
      " [ 0  0  0 10  0]\n",
      " [ 0  0  0  0 26]] \n",
      "\n",
      "c) Precision, Recall, and F1-measure using the Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       drugA       1.00      1.00      1.00         5\n",
      "       drugB       1.00      0.67      0.80         3\n",
      "       drugC       1.00      0.83      0.91         6\n",
      "       drugX       0.91      1.00      0.95        10\n",
      "       drugY       0.96      1.00      0.98        26\n",
      "\n",
      "    accuracy                           0.96        50\n",
      "   macro avg       0.97      0.90      0.93        50\n",
      "weighted avg       0.96      0.96      0.96        50\n",
      "\n",
      "d) Accuracy, Macro-Average F1 and Weighted-Average F1\n",
      "Accuracy =  0.96\n",
      "MacroF1score =  0.9285207873887119\n",
      "WeightedF1score =  0.9577557788123826\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Model f: Top MLP')\n",
    "print('b) The Confusion matrix') \n",
    "print('Hyperparameter values: ')\n",
    "print('solver = adam, sgd; Activation function = logistic, tanh, relu, identity')\n",
    "print('network architecture = (30, 50), (10, 10, 10)')\n",
    "print('Best hyperparameters found:')\n",
    "ConfusionMatrix6 = metrics.confusion_matrix(Y_test, classPredMLP_top)\n",
    "print(ConfusionMatrix6, '\\n')\n",
    "print('c) Precision, Recall, and F1-measure using the Classification Report')\n",
    "print(classification_report(Y_test, classPredMLP_top))\n",
    "print('d) Accuracy, Macro-Average F1 and Weighted-Average F1')\n",
    "Accuracy6 = metrics.accuracy_score(Y_test, classPredMLP_top)\n",
    "MacroF1score6 = f1_score(Y_test, classPredMLP_top, average='macro')\n",
    "WeightedF1score6 = f1_score(Y_test, classPredMLP_top, average='weighted')\n",
    "\n",
    "print('Accuracy = ', Accuracy6)\n",
    "print('MacroF1score = ', MacroF1score6)\n",
    "print('WeightedF1score = ', WeightedF1score6)\n",
    "print('--------------------------------------------------------------------------------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
